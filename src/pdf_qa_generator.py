import os
from colorama import Fore
import json
from typing import List
from pydantic import BaseModel
from litellm import completion
from generated_prompt import prompt_template

class SimpleChunk:
    """Markdown iÃ§in basit chunk sÄ±nÄ±fÄ±"""
    def __init__(self, text: str, section_name: str = ""):
        self.text = text
        self.section_name = section_name

def extract_text_from_markdown(md_path: str) -> List[SimpleChunk]:
    """Markdown dosyasÄ±ndan metin Ã§Ä±karma ve chunk'lara bÃ¶lme"""
    chunks = []
    try:
        with open(md_path, 'r', encoding='utf-8') as file:
            content = file.read()
            print(f"{Fore.CYAN}Markdown dosyasÄ± okundu: {len(content)} karakter{Fore.RESET}")
            
            sections = content.split('\n\n')
            current_section = ""
            current_text = ""
            
            for section in sections:
                section = section.strip()
                if not section:
                    continue
                    
                if section.startswith('#'):
                    if current_text and len(current_text.strip()) > 100:
                        chunks.append(SimpleChunk(
                            text=current_text.strip(),
                            section_name=current_section
                        ))
                    
                    current_section = section
                    current_text = section + "\n\n"
                else:
                    current_text += section + "\n\n"
                    
                    if len(current_text) > 3000:
                        chunks.append(SimpleChunk(
                            text=current_text.strip(),
                            section_name=current_section
                        ))
                        current_text = ""
            
            if current_text and len(current_text.strip()) > 100:
                chunks.append(SimpleChunk(
                    text=current_text.strip(),
                    section_name=current_section
                ))
                
    except Exception as e:
        print(f"{Fore.RED}Markdown okuma hatasÄ±: {e}{Fore.RESET}")
        return []
    
    print(f"{Fore.GREEN}Toplam {len(chunks)} chunk oluÅŸturuldu{Fore.RESET}")
    return chunks

# Mevcut dataquality.py'den alÄ±nan kalite kontrol sÄ±nÄ±flarÄ±
class Score(BaseModel):
    score: int
    explanation: str

class Rank(BaseModel):
    accuracy: Score
    style: Score

class Record(BaseModel):
    question: str
    answer: str

class Response(BaseModel):
    generated: List[Record]

def llm_call(data: str, num_records: int = 5) -> dict:
    """PDF chunk'Ä±ndan soru-cevap Ã§iftleri Ã¼retir"""
    try:
        stream = completion(
            model="ollama/gemma2:2b",
            messages=[
                {
                    "role": "user",
                    "content": prompt_template(data, num_records),
                }
            ],
            stream=True,
            options={"num_predict": 2000, "temperature": 0.3},
        )
        
        response_data = ""
        for x in stream: 
            delta = x['choices'][0]["delta"]["content"]
            if delta is not None: 
                print(Fore.LIGHTBLUE_EX + delta + Fore.RESET, end="") 
                response_data += delta 
        
        if not response_data.strip():
            print(f"{Fore.YELLOW}BoÅŸ response alÄ±ndÄ±{Fore.RESET}")
            return {"generated": []}
        
        parsed_data = extract_json_from_response(response_data)
        if parsed_data:
            return {"generated": parsed_data}
        else:
            print(f"{Fore.RED}JSON parse edilemedi{Fore.RESET}")
            return {"generated": []}
            
    except Exception as e:
        print(f"{Fore.RED}LLM Ã§aÄŸrÄ±sÄ±nda hata: {e}{Fore.RESET}")
        return {"generated": []}

def extract_json_from_response(response_text: str) -> dict:
    """Response'dan JSON'Ä± Ã§Ä±karmaya Ã§alÄ±ÅŸÄ±r - tÃ¼m edge case'leri handle eder"""
    
    cleaned = response_text.strip()
    
    if cleaned.startswith("```json"):
        cleaned = cleaned[7:]
    elif cleaned.startswith("```"):
        cleaned = cleaned[3:]
    
    if cleaned.endswith("```"):
        cleaned = cleaned[:-3]
    
    cleaned = cleaned.strip()
    
    json_start = -1
    
    array_start = cleaned.find('[')
    if array_start != -1:
        json_start = array_start
    
    if json_start == -1:
        object_start = cleaned.find('{')
        if object_start != -1:
            json_start = object_start
    
    if json_start == -1:
        print(f"{Fore.YELLOW}JSON start karakteri bulunamadÄ±{Fore.RESET}")
        return None
    
    json_text = cleaned[json_start:]
    
    try:
        return json.loads(json_text)
    except json.JSONDecodeError:
        return find_last_valid_json(json_text)

def find_last_valid_json(text: str) -> dict:
    """Text'te en son geÃ§erli JSON'Ä± bulmaya Ã§alÄ±ÅŸÄ±r"""
    
    last_brace = text.rfind('}')
    last_bracket = text.rfind(']')
    
    if last_brace == -1 and last_bracket == -1:
        return None
    
    end_pos = max(last_brace, last_bracket) + 1
    
    for start_pos in range(len(text)):
        try:
            json_text = text[start_pos:end_pos]
            result = json.loads(json_text)
            print(f"{Fore.GREEN}JSON bulundu: {start_pos}-{end_pos}{Fore.RESET}")
            return result
        except json.JSONDecodeError:
            continue
    
    return None

def quality_check_qa_pair(qa_pair: dict) -> dict:
    """Tek bir soru-cevap Ã§iftinin kalitesini kontrol eder"""
    record = f"Question: {qa_pair['question']}\nAnswer: {qa_pair['answer']}"
    
    for attempt in range(3):
        try:
            stream = completion(
                model="ollama/gemma2:2b",
                messages=[
                    {
                        "role": "user",
                        "content": f"""Evaluate this question-answer pair and rate accuracy and style from 1-10.

Question-Answer Pair:
{record}

Rate the pair and return ONLY this JSON format:

```json
{{
  "accuracy": {{
    "score": 8,
    "explanation": "Your explanation here"
  }},
  "style": {{
    "score": 7,
    "explanation": "Your explanation here"
  }}
}}
```

Rating Guidelines:
- Accuracy 1-3: Wrong/incomplete answers
- Accuracy 4-6: Partially correct answers  
- Accuracy 7-10: Correct and complete answers
- Style 1-3: Poor grammar/unclear
- Style 4-6: Average clarity
- Style 7-10: Clear and well-written

IMPORTANT: Return ONLY the JSON, no additional text.""",
                    }
                ],
                stream=True,
                options={"num_predict": 500, "temperature": 0.1},
                timeout=30,  # 30 saniye timeout
            )
        
            data = ""
            for x in stream: 
                delta = x['choices'][0]["delta"]["content"]
                if delta is not None: 
                    data += delta 
            
            if not data.strip():
                print(f"{Fore.YELLOW}Kalite kontrol: BoÅŸ response alÄ±ndÄ± (Deneme {attempt+1}){Fore.RESET}")
                if attempt == 2:  # Son deneme
                    return {
                        "accuracy": {"score": 1, "explanation": "BoÅŸ response"},
                        "style": {"score": 1, "explanation": "BoÅŸ response"}
                    }
                continue
            
            parsed_data = extract_json_from_response(data)
            if parsed_data:
                return parsed_data
            else:
                print(f"{Fore.YELLOW}Kalite kontrol JSON parse edilemedi (Deneme {attempt+1}){Fore.RESET}")
                if attempt == 2:  # Son deneme
                    return {
                        "accuracy": {"score": 1, "explanation": "JSON parse hatasÄ±"},
                        "style": {"score": 1, "explanation": "JSON parse hatasÄ±"}
                    }
                continue
                
        except Exception as e:
            print(f"{Fore.YELLOW}Kalite kontrolÃ¼nde hata (Deneme {attempt+1}): {e}{Fore.RESET}")
            if attempt == 2:  # Son deneme
                return {
                    "accuracy": {"score": 1, "explanation": f"Error: {str(e)}"},
                    "style": {"score": 1, "explanation": f"Error: {str(e)}"}
                }
            import time
            time.sleep(2)  # 2 saniye bekle
            continue
    
    return {
        "accuracy": {"score": 1, "explanation": "TÃ¼m denemeler baÅŸarÄ±sÄ±z"},
        "style": {"score": 1, "explanation": "TÃ¼m denemeler baÅŸarÄ±sÄ±z"}
    }

def process_markdown_to_qa(md_path: str, output_file: str = "markdown_qa_dataset.json", quality_output_file: str = "markdown_qa_quality.json", min_quality_score: int = 6):
    """
    Markdown dosyasÄ±nÄ± iÅŸleyip kaliteli soru-cevap Ã§iftleri Ã¼retir
    """
    print(f"{Fore.GREEN}Markdown iÅŸleniyor: {md_path}{Fore.RESET}")
    
    chunks = extract_text_from_markdown(md_path)
    
    if not chunks:
        print(f"{Fore.RED}Markdown dosyasÄ±ndan chunk Ã§Ä±karÄ±lamadÄ±!{Fore.RESET}")
        return
    
    print(f"{Fore.YELLOW}Toplam {len(chunks)} chunk bulundu{Fore.RESET}")
    
    high_quality_pairs = []
    quality_results = []
    
    print(f"{Fore.CYAN}ğŸš€ Chunk bazÄ±nda QA Ã¼retimi ve kalite kontrol baÅŸlÄ±yor...{Fore.RESET}")
    
    for i, chunk in enumerate(chunks):
        print(f"\n{Fore.CYAN}Chunk {i+1}/{len(chunks)} iÅŸleniyor...{Fore.RESET}")
        if chunk.section_name:
            print(f"{Fore.LIGHTMAGENTA_EX}BÃ¶lÃ¼m: {chunk.section_name[:50]}...{Fore.RESET}")
        print(f"{Fore.YELLOW}Metin UzunluÄŸu: {len(chunk.text)} karakter{Fore.RESET}")
        
        generated_data = llm_call(chunk.text, num_records=3)
        
        if "generated" in generated_data:
            chunk_qa_pairs = generated_data["generated"]
            print(f"{Fore.GREEN}âœ“ {len(chunk_qa_pairs)} soru-cevap Ã§ifti Ã¼retildi{Fore.RESET}")
            
            print(f"{Fore.YELLOW}ğŸ” Kalite kontrol baÅŸlÄ±yor...{Fore.RESET}")
            chunk_high_quality = []
            chunk_quality_results = []
            
            for qa_pair in chunk_qa_pairs:
                quality_assessment = quality_check_qa_pair(qa_pair)
                
                try:
                    if isinstance(quality_assessment, dict):
                        if 'accuracy' in quality_assessment and 'style' in quality_assessment:
                            accuracy_score = quality_assessment['accuracy']['score'] if isinstance(quality_assessment['accuracy'], dict) else quality_assessment['accuracy']
                            style_score = quality_assessment['style']['score'] if isinstance(quality_assessment['style'], dict) else quality_assessment['style']
                        else:
                            accuracy_score = 1
                            style_score = 1
                    else:
                        accuracy_score = 1
                        style_score = 1
                except Exception as e:
                    print(f"{Fore.YELLOW}Kalite score hatasÄ±: {e}{Fore.RESET}")
                    accuracy_score = 1
                    style_score = 1
                
                chunk_quality_results.append({**qa_pair, 'quality': quality_assessment})
                
                if accuracy_score >= min_quality_score and style_score >= min_quality_score:
                    chunk_high_quality.append(qa_pair)
                    print(f"{Fore.GREEN}âœ“ YÃ¼ksek kalite (A:{accuracy_score}, S:{style_score}){Fore.RESET}")
                else:
                    print(f"{Fore.RED}âœ— DÃ¼ÅŸÃ¼k kalite (A:{accuracy_score}, S:{style_score}){Fore.RESET}")
            
            high_quality_pairs.extend(chunk_high_quality)
            quality_results.extend(chunk_quality_results)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(high_quality_pairs, f, ensure_ascii=False, indent=4)
            
            with open(quality_output_file, 'w', encoding='utf-8') as f:
                json.dump(quality_results, f, ensure_ascii=False, indent=4)
            
            print(f"{Fore.GREEN}ğŸ’¾ Dosyalar gÃ¼ncellendi! Toplam {len(high_quality_pairs)} yÃ¼ksek kaliteli QA{Fore.RESET}")
    
    print(f"\n{Fore.GREEN}ğŸ‰ TÃœM Ä°ÅLEMLER TAMAMLANDI!{Fore.RESET}")
    
    print(f"\n{Fore.CYAN}ğŸ“Š Ä°STATÄ°STÄ°KLER:{Fore.RESET}")
    print(f"Toplam chunk: {len(chunks)}")
    print(f"Toplam Ã¼retilen QA: {len(quality_results)}")
    print(f"YÃ¼ksek kaliteli QA: {len(high_quality_pairs)}")
    
    if len(quality_results) > 0:
        print(f"BaÅŸarÄ± oranÄ±: {(len(high_quality_pairs)/len(quality_results)*100):.1f}%")
    else:
        print(f"BaÅŸarÄ± oranÄ±: 0% (HiÃ§ QA Ã¼retilmedi)")
    
    print(f"\n{Fore.GREEN}âœ… YÃ¼ksek kaliteli soru-cevap Ã§iftleri '{output_file}' dosyasÄ±na kaydedildi.{Fore.RESET}")
    print(f"{Fore.GREEN}âœ… TÃ¼m kalite deÄŸerlendirme sonuÃ§larÄ± '{quality_output_file}' dosyasÄ±na kaydedildi.{Fore.RESET}")

if __name__ == "__main__":
    process_markdown_to_qa(
        md_path=r"C:\Users\hamdi\Desktop\fine_tuning_reasoning_model\data\using-manufacturing.md",
        output_file="data/tm1_qa_high_quality.json",
        quality_output_file="data/tm1_qa_quality_report.json",
        min_quality_score=6
    )
